---
title: "Regresión Lineal Múltiple I"
author: "Juan Barriola y Sofía Perini"
date: "3 de Octubre de 2020"
output:
  html_notebook:
    theme: spacelab
    toc: yes
    toc_float: yes
    df_print: paged
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>
  
## Planteo del problema

Nuestro objetivo es crear un modelo lineal múltiple para explicar el sueldo neto de Data Analysts, Data Scientists y Data Engineers en Argentina.

Nuestra idea subyacente de cómo se puede explicar el salario neto es:

$salarioNeto = \beta_0 +\beta_1X_1+\beta_2X_2+...+\epsilon$

```{r, warning=F, message=F}
library(tidyverse)
library(tidymodels)
```

## Levantamos Dataset

Vamos a trabajar con el subconjunto de datos que surgió del trabajo de limpieza que se hizo en la clase de regresión lineal simple, correspondiente al grupo de salarios de los data scientists/analyst, de la encuesta de sueldos en el sector de tecnología en Argenina realizada por SysArmy. El informe, realizado por OpenQube lo pueden ver [acá](https://sueldos.openqube.io/encuesta-sueldos-2020.01/).

```{r, message=F}
encuesta <- read_csv("../Fuentes/encuesta_RLM_limpia.csv")
```
La limpieza consistió en: eliminar los outliers de acuerdo a los criterios de la clase 3, descartar los sueldos dolarizados, eliminar los registros inconsistentes con la edad laboral, aquellas inconsistencias en las variables sueldo bruto y neto, como también aquellos errores de carga en los años de experiencia y las inconsistencias en relación con los años en la empresa actual, quedando como resultado un dataset de 159 observaciones, con el que trabajaremos a continuación (98 DA y 61 DS). 

### Seleccionamos variables de interés

```{r}
df <- encuesta %>%
  select(me_identifico, edad, donde_estas_trabajando, anos_de_experiencia, anos_en_la_empresa_actual, anos_en_el_puesto_actual, gente_a_cargo, trabajo_de, nivel_de_estudios_alcanzado, estado, salario_bruto, salario_neto) %>%
  # creamos la variable perfil
  mutate(perfil = factor(case_when(trabajo_de == "BI Analyst / Data Analyst" ~ "DA", trabajo_de == "Data Scientist / Data Engineer" ~ "DS")))
df %>%
  head()
```
Recordemos cómo era la correlación entre las variables numéricas seleccionadas. 

```{r, message=FALSE, warning=FALSE, fig.width=8, fig.height=6}
library(GGally)
df %>%
  select(edad, anos_de_experiencia, anos_en_la_empresa_actual, anos_en_el_puesto_actual, gente_a_cargo, salario_neto, perfil) %>% 
  ggpairs(., aes(color = perfil), 
          upper = list(continuous = wrap("cor", size = 3, hjust=0.5)), legend = 25) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, vjust=0.5), legend.position = "bottom")
```

## Modelo Múltiple

El modelo de **regresión lineal múltiple** es un modelo para la variable aleatoria Y cuando se conocen las variables regresoras. Es múltiple ya que vincula una serie de variables predictoras con Y. 

El modelo en términos de las variables:

$$Y_i = β_0 + β_1X_{i1} + β_2X_{i2} + · · · + β_{p-1}X_{ip-1} + ε_i$$
donde $β_0$, $β_1$,.., $β_{p−1}$ son parámetros desconocidos, $X_{i1}$, $X_{i2}$, ..., $X_{ip-1}$ son los valores de las variables predictoras medidas en el i-ésimo individuo, $Y_i$ es la variable respuesta medida en el i-ésimo individuo (observado) y $ε_i$ es el error para el individuo i-ésimo (no observable).

**Supuestos del modelo lineal**

Se pueden resumir como $ϵ_i$ ~ $N(0,σ^2)$ para todo $1<i<n$, independientes entre sí.

El modelo en términos de la esperanza condicional de Y dadas $X_1$, $X_2$,..., $X_{p-1}$:

$$E(Y|X_1,X_2,...X_{p-1}) = β_0 + β_1X_{i1} + β_2X_{i2} + · · · + β_{p-1}X_{ip-1}$$

El modelo se denomina *lineal* puesto que la esperanza de Y condicional a las X's depende linealmente de las covariables $X_1$, $X_2$,..., $X_{p-1}$. 

### Estimación de los Parámetros (ajuste del modelo)

Se quiere ajustar un modelo para el salario neto en función de 2 variables:

$salarioNeto = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \epsilon_i$

Veamos cómo se interpretan los ajustes para los distintos tipos de predictores. 

### *1) Predictores numéricos*

Armemos un modelo para predecir el salario_neto en función de los años de experiencia y la gente_a_cargo. Veamos los resultados del modelo empleando la función tidy(). 

```{r}
# ajustamos modelo lineal multiple
modelo_exp_gc <- lm(salario_neto ~ anos_de_experiencia + gente_a_cargo, data = df)
# Resumen del modelo
tidy_meg <- tidy(modelo_exp_gc, conf.int = TRUE)
tidy_meg
```

#### Significado de los coeficientes estimados

* El valor de la ordenada al origen (61.303) es el valor de salario neto **esperado** para alguien sin experiencia laboral (0 años de experiencia) y sin gente a cargo, es decir, para alguien que recién comienza. 

* El coeficiente estimado de años de experiencia  es 967,23. Si mantenemos el número de gente a cargo constante, cada incremento de un año en los años de experiencia corresponde a un aumento de 967 pesos, **en promedio** en el sueldo neto. O lo que es igual, dadas dos personas con la misma cantidad de gente a cargo pero teniendo uno un año más de experiencia que el otro, el sueldo neto **esperado** para el de mayor experiencia será 967 pesos más alto que el de menor experiencia.

¿Cómo se interpretaría el coeficiente estimado de gente a cargo?

### *2) Predictores Categóricos*

### *i) Predictor binario*

Armemos un modelo para predecir el salario_neto en función de los años de experiencia y el género (me_identifico), que es categórica con dos niveles (hombres y mujeres). Para ello, vamos a analizar primero el comportamiento de la variable que queremos predecir para ambos géneros a través de un boxplot. 

```{r}
# armamos boxplots paralelos de salario neto según género
ggplot(data = df, aes(y=salario_neto/1000, group = me_identifico, fill = me_identifico)) +
         geom_boxplot() + 
         scale_fill_brewer(palette="Dark2") +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
         labs(title = "Boxplots de salario neto según género", subtitle = "En miles de pesos") +
  facet_wrap(~me_identifico)
```

Veamos qué ocurre cuando **ajustamos el modelo**:

```{r}
# ajustamos el modelo
modelo_exp_sex <- lm(salario_neto ~ anos_de_experiencia + me_identifico, data = df)
tidy_mes <- tidy(modelo_exp_sex, conf.int = TRUE)
tidy_mes
```

#### Significado de los coeficientes estimados

¿Cómo cambia la **interpretación** de los coeficientes para la variable dicotómica?

* El modelo de regresión lineal en este caso consiste simplemente en expresar
la media del nivel de sueldo neto en cada población (de hombres y mujeres) mediante dos coeficientes distintos, donde $\beta_0$ es la media del sueldo neto para los hombres y $\beta_0 + \beta_2$ es la media del salario neto para las mujeres, dados los años de experiencia. Por lo tanto, $\beta_2$ es la diferencia (en este caso negativa) en los **niveles medios** de salario neto de las mujeres respecto de los hombres (categoría basal).

* Vemos que el nivel medio del sueldo neto es una función lineal de los años de experiencia de la persona, con una misma pendiente $\beta_1$ (896) para mujeres y hombres. Por otro lado, $\beta_2$ (-12.850) indica cuánto más baja es la función de respuesta (sueldo) para las mujeres respecto de los hombres (categoría basal), dados los años de experiencia.

#### Grafiquemos la regresión para ambas poblaciones

A continuación se muestra el gráfico de esta situación en que tenemos una variable categórica con solo dos niveles y una numérica. De la interpretación de coeficientes, se pudo ver que la regresión se puede expresar como dos rectas paralelas con igual pendiente pero distinto intercepto. Veamos cómo hacerla. 

```{r}
# Accedemos a la información de los coeficientes estimados
intercepto_H = modelo_exp_sex$coefficients[1] # β0
pendiente1 = modelo_exp_sex$coefficients[2] # β1
intercepto_M = modelo_exp_sex$coefficients[1] + modelo_exp_sex$coefficients[3] # β0 + β2
# Graficamos el dataset y el modelo
df %>% ggplot(., aes(x = anos_de_experiencia, y = salario_neto)) + 
  geom_abline(intercept = intercepto_H, slope = pendiente1, color = "forestgreen", size=1.5) + # capa del modelo
  geom_abline(intercept = intercepto_M, slope = pendiente1, color = "darkorange", size=1.5) + # capa del modelo 
  geom_point() + #capa de los datos
  theme_bw() +
  scale_x_continuous(limits = c(0,40)) +
  scale_y_continuous(limits = c(0,150000)) +
  labs(title="Modelo Lineal Múltiple: Años en la empresa y Género", x="Años de experiencia", y="Salario Neto") 
```

### *ii) Predictores Cualitativos con más de dos clases*

Como hay dos variables que se refieren al nivel de estudios alcanzado, vamos a unificar en una misma y reagrupar los datos.

```{r}
# armamos nuevas variables de nivel educativo y educativo alcanzado
df2 <- df %>% 
  mutate(nivel_educativo = case_when(nivel_de_estudios_alcanzado %in% c("Posgrado", "Posdoctorado", "Doctorado") ~ "Posgrado", 
                                     TRUE ~ nivel_de_estudios_alcanzado),
         # unificamos nivel educativo y estado 
         nivel_edu_alcanzado = paste(nivel_educativo, sep = " ", estado)) 
unique(sort(df2$nivel_edu_alcanzado)) # quedan 9 categorías
```

Quedan 9 categorías de nivel educativo alcanzado. Veamos a través de boxplots paralelos cómo se comportan. 

```{r}
# graficamos los boxplot paralelos
ggplot(data = df2, aes(y=salario_neto/1000, group = nivel_edu_alcanzado, fill = nivel_edu_alcanzado)) +
         geom_boxplot() +
         theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(title = "Boxplots de salario neto según nivel educativo alcanzado", subtitle = "En miles de pesos")
```

Probemos **ajustar un modelo lineal** para el sueldo neto en función de los años de experiencia y esta nueva variable de nivel_edu_alcanzado.  

```{r}
# ajustamos el modelo
modelo_exp_edu <- lm(salario_neto ~ anos_de_experiencia + nivel_edu_alcanzado, data = df2)
tidy_meed <- tidy(modelo_exp_edu, conf.int = TRUE)
tidy_meed
```

R cuando efectúa la regresión calcula automáticamente las variables indicadoras (dummies) para las covariables categóricas, en general según orden alfabético. Podemos chequear el orden para verificar cuál es la categoría basal. En este caso, la categoría de referencia corresponde al nivel educativo *Posgrado Completado*.

#### Significado de los coeficientes estimados

¿Qué significan los coeficientes de la nueva variable categórica?

* Este modelo propone ajustar una recta distinta para el sueldo neto **medio**
de cada grupo de personas definido por el nivel educativo alcanzado, todas con igual pendiente (definida por los años de experiencia), y nueve ordenadas al origen diferentes, una por cada grupo (nivel educativo alcanzado).

* Por ejemplo, $\beta_2$ = nivel_edu_alcanzado **Posgrado En curso**, indica cuánto se reduce el sueldo neto medio para las personas cuyo nivel educativo es Posgrado En curso respecto de aquellas cuyo nivel es Posgrado Completado (categoría basal), dados los años de experiencia.

```{r}
# Accedemos a la información de los coeficientes estimados
intercepto_1 = modelo_exp_edu$coefficients[1]
pendiente_meed = modelo_exp_edu$coefficients[2]
intercepto = c()
for (i in 3:9) {
  intercepto[i] = modelo_exp_edu$coefficients[1] + modelo_exp_edu$coefficients[i]
 }
# Graficamos el dataset y el modelo
df %>% 
  ggplot(., aes(x = anos_de_experiencia, y = salario_neto)) + 
  geom_abline(intercept = intercepto_1, slope = pendiente_meed, color = "forestgreen", size=1) +
  geom_abline(intercept = intercepto[3], slope = pendiente_meed, color = "darkorange", size=1) + 
    geom_abline(intercept = intercepto[4], slope = pendiente_meed, color = "red", size=1) + 
    geom_abline(intercept = intercepto[5], slope = pendiente_meed, color = "violet", size=1) +  
    geom_abline(intercept = intercepto[6], slope = pendiente_meed, color = "blue", size=1) +  
    geom_abline(intercept = intercepto[7], slope = pendiente_meed, color = "black", size=1) +  
    geom_abline(intercept = intercepto[8], slope = pendiente_meed, color = "brown", size=1) + 
    geom_abline(intercept = intercepto[9], slope = pendiente_meed, color = "yellow", size=1) + 
  geom_point() +
  theme_bw() +
  scale_x_continuous(limits = c(0,40)) +
  scale_y_continuous(limits = c(0,150000)) +
  labs(title="Modelo Lineal Múltiple: Años en la empresa y Nivel Educativo", x="Años de experiencia", y="Salario Neto") 
```

## Inferencia de los $β_k$ (test de significatividad individual)

#### Test para las $β_k$

Para evaluar la significativdad individual de cada una de las variables se analiza el test t que busca probar si el coeficiente de regresión correspondiente a dicha variable es distinto de 0 (figura en la tabla resumen de resultados de la regresión).

Es decir, busca probar:  

* $H_0: \hat{\beta_k} = 0$ 

* $H_1: \hat{\beta_k} ≠ 0$. 

**Modelo Años de experiencia y Gente a cargo**

```{r}
options(scipen=1)
# Modelo Años de experiencia y gente a cargo
tidy_meg %>%
  select(term, statistic, p.value, conf.low, conf.high)
```

* En este primer modelo se observa que la variable años de experiencia resulta estadísticamente significativa para explicar al sueldo neto (p-valor = 0.001 < 0.05), mientras que la gente a cargo no (p-valor = 0.84 > 0.05). 

* Además del resultado del test, podemos apreciar que el intervalo de confianza (IC) del 95% de la variable años de experiencia no contiene al 0, mientras el IC de la variable gente_a_cargo sí. 

**Modelo Años de experiencia y Género**

```{r}
# Modelo Años de experiencia y Género
tidy_mes %>%
  select(term, statistic, p.value, conf.low, conf.high)
```

* En este caso se observa que la variable años de experiencia y la categoría Mujer de la variable me_identifico resultan estadísticamente significativas para explicar al sueldo neto (p-valores < 0.05). 

* Además del resultado del test, podemos corroborar que los intervalos de confianza del 95% para los coeficientes estimados no contienen al 0 en ninguno de los casos.  

##### ¿Cómo se interpreta la significatividad de las variables dummies?

* En el caso de la variable dicotómica me_identifico (género), este test permite chequear si los valores medios del sueldo neto son los mismos para las mujeres respecto de los hombres (categoría basal).

**Modelo Años de experiencia y Nivel Educativo Alcanzado** 

```{r}
# Modelo Años de experiencia y Nivel Educativo Alcanzado
tidy_meed %>%
  select(term, statistic, p.value, conf.low, conf.high) %>% 
  arrange(p.value)
```

* En este modelo se observa que mientras la variable años de experiencia resulta estadísticamente significativa para explicar al sueldo neto (p-valores < 0.05), las categorías de nivel educativo no. Hay algunas que resultan significativas y otras no.

* Esto mismo se observa a través de los intervalos de confianza del 95% donde algunos contienen al 0 (por ej. Terciario Incompleto) y otros no (por ej. Universitario En Curso).  

##### ¿Cómo se interpreta la significatividad de las variables indicadoras?

* Este test permite chequear si los valores medios del sueldo neto son los mismos en las distintas categorías de nivel educativo alcanzado respecto de la categoría basal. Cabe destacar, que estos p-valores son válidos para las comparaciones individuales respecto de la categoría basal pero no abarcan todas las comparaciones de a pares.

* Es decir, que los niveles medios de sueldo neto en los distintos grupos del nivel educativo alcanzado en algunos casos difieren del basal y en otros no.

* Si queremos evaluar a la variable nivel_edu_alcanzado en su conjunto, debemos recurrir a un test F. 

## Test F (test de significatividad global)

El test conjunto F (y su correspondiente p-valor) permite medir la significatividad conjunta de una variable categórica para explicar la respuesta.

Test F se construye para testear si varios parámetros son cero, es decir, para probar las hipótesis:

* $H_0: β_1 = β_2 = · · · = β_{p−1} = 0$

* $H_1:$ no todos los $β_k$ ($k = 1, 2,..., p−1$) son iguales a 0. 

Dichos tests F se obtienen para cada variable de la tabla de ANOVA del modelo. Veamos qué ocurre en este caso. 

```{r}
# Modelo Años de experiencia y Nivel Educativo Alcanzado
tidy(anova(modelo_exp_edu))
```

La tabla de ANOVA muestra que, según el resultado del test F, la variable nivel educativo alcanzado en su conjunto no resulta estadísticamente significativa para explicar al sueldo neto (p-valor > 0.05).

Si este test no resulta significativo, suele descartarse la variable categórica de entre las covariables de interés, y se la excluye del modelo. Por el contrario, si este test resulta estadísticamente significativo, entonces suelen mirarse con más detalle cuáles de las comparaciones entre grupos son estadísticamente significativas, para proporcionar un mejor análisis de los datos. 

### Colinealidad de los Predictores

Cuando las variables predictoras están correlacionadas entre sí, decimos que existe intercorrelación o multicolinealidad. 

¿Qué pasa en nuestro dataset con los años de experiencia y de edad?

```{r}
cor(df2$anos_de_experiencia, df2$edad)
```
Como ya habíamos visto en el gráfico ggpairs inicial, estas variables tienen alta correlación. Veamos qué ocurre con los coeficientes de ambas variables al armar distintos modelos múltiples que las incluyan. 

Armamos un **modelo con edad, años de experiencia, gente a cargo y género**. 

```{r}
modelo_4 <- lm(salario_neto ~ anos_de_experiencia + edad + gente_a_cargo + me_identifico, data = df2)
tidy(modelo_4)
```

Armamos un **modelo con edad y años de experiencia**. 

```{r}
modelo_exp_edad <- lm(salario_neto ~ anos_de_experiencia + edad, data = df2)
tidy(modelo_exp_edad)
```

Armamos un **modelo con los años de experiencia, gente a cargo y género** pero sin contemplar la edad. 

```{r}
modelo_3 <- lm(salario_neto ~ anos_de_experiencia + gente_a_cargo + me_identifico, data = df2)
tidy(modelo_3)
```

##### ¿Qué diferencias encuentran con los coeficientes de edad y años de experiencia en los 3 modelos?

* Los coeficientes de regresión estimados se modifican sustancialmente cuando agregamos o quitamos variables del modelo. En el modelo_4 vs exp_edad el beta estimado de los años de experiencia cambia de 974 a 919 y la edad de -80 a 48. 
* Los errores estándares de los estimadores de los coeficientes aumentan espúreamente cuando se incluyen covariables muy correlacionadas. Se infla la varianza estimada de los estimadores. En nuestro caso: el error estándar de la variable años de experiencia en el modelo_4 donde está incluida la edad es de alrededor de 557, mientras que en el modelo_3 que se excluye dicha variable es de 287.

* En el modelo de experiencia y edad, los p-valores de los coeficientes estimados superan el umbral de 0.10. Es decir, ninguno de los dos resulta significativo cuando ambas variables están en el modelo.

Veamos qué ocurre si en vez de usar los años de experiencia en el modelo_3 usamos la edad.

```{r}
tidy(lm(salario_neto ~ edad + gente_a_cargo + me_identifico, data = df2))
```

Observamos que ahora sí resulta estadísticamente significativa la edad para explicar el sueldo neto. 

Los coeficientes pueden ser no significativos aún cuando exista una asociación verdadera entre la variable de respuesta y el conjunto de regresoras cuando armamos un modelo con multicolinealidad de variables regresoras. 

> Hay que tener cuidado con la colinealidad de los predictores para no tener problemas con la interpretación de los coeficientes del modelo lineal y que no aumenten espúreamente la varianza estimada de los estimadores. 

### Observaciones sobre la interpretación de los coeficientes

Supongamos que consideramos el siguiente modelo para explicar el salario neto: 
$E(salarioNeto|...) = \beta_0 + \beta_1AñosExperiencia + \beta_2AñosEmpresaActual$

##### ¿Cuál es la interpretación correcta del parámetro estimado $\beta_2$?

Comencemos analizando la correlación entre estas variables:

```{r}
cor(df2$anos_de_experiencia, df2$anos_en_la_empresa_actual)
```
Tiene una correlación positiva bastante fuerte. 

Construimos el modelo lineal que planteamos 

**Modelo experiencia y experiencia en la empresa actual**

```{r}
# modelo 1: salario en función de anos de experiencia y anos en empresa actual
tidy(lm(salario_neto ~ anos_de_experiencia + anos_en_la_empresa_actual, data = df2))
```

La interpretación de los coeficientes estimados es:

* $\hat{\beta_1}=1068$ indica que por cada año de experiencia adicional el salario neto **esperado** aumenta en 1068 pesos dados los años de en la empresa actual.

* $\hat{\beta_2}=-431$ indica que por cada año adicional en la empresa actual el salario neto **esperado** disminuye en -431 pesos dados los años de experiencia.

Respecto a la segunda interpretación alguien podría objetar lo siguiente:

$AñosExperiencia = AñosEmpresaActual + AñosEmpresasPasadas$

Entonces, si aumento en un año la variable AñosEmpresaActual no puedo sostener que variable AñosExperiencia se mantiene constante.

¿Es esta observación correcta?

No, el coeficiente de $\hat{\beta_2}$ nos permite evaluar cual es el efecto en el salario neto esperado de estar un año más en la misma empresa para igual cantidad de años de experiencia.

Por ejemplo, si existen dos personas con 5 años de experiencia en total y la persona A está hace 2 años en la empresa actual y la persona B está hace 3 años, nuestro modelo nos indica que el salario predicho para la persona B va a ser 431 menor al salario de la persona A.

De todas maneras, observamos que el p valor asociado a $\beta_2$ indica que no se puede rechazar la hipotesis nula del test de significatividad individual.

**Modelo experiencia previa y experiencia actual**

Si quisieramos poder separar el efecto de los años de experiencia previa y experiencia actual deberíamos crear una variable nueva que sea:

$AñosExperienciaPrevia = AñosExperiencia - AñosEmpresaActual$

Ahora nuestro modelo es:

$E(salarioNeto|...) = \beta_0 + \beta_1AñosExperienciaPrevia + \beta_2AñosEmpresaActual$

```{r}
# armamos nueva variable de experiencia previa
df3 <- df2 %>%
  mutate(exp_previa = anos_de_experiencia - anos_en_la_empresa_actual)
# modelo 2: separando experiencia previa y empresa actual  
tidy(lm(salario_neto ~ exp_previa + anos_en_la_empresa_actual, data = df3))
```

La interpretación de los coeficientes estimados es:

* $\hat{\beta_1}=1068$ indica que por cada año de experiencia previa el salario neto **esperado** aumenta en 1068 pesos, dados los años de en la empresa actual.

* $\hat{\beta_2}=637$ indica que por cada año adicional en la empresa actual el salario neto **esperado** aumenta en 637 pesos dados los años de experiencia previa.

En este caso la regresión ayuda a entender cómo afecta la experiencia previa y la actual el sueldo neto. Es decir, cuánto aumenta el sueldo neto medio un año adicional de experiencia previa, dados los años en la empresa actual, y cuánto aumenta el sueldo neto promedio un año adicional de experiencia en la empresa actual, dada la experiencia previa. 

Volvemos a observar que el p valor asociado a $\beta_2$ indica que no se puede rechazar la hipotesis nula del test de significatividad individual.